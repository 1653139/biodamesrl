[data]
train : data/srl/samples/train-set-3-percent
dev : data/srl/samples/dev-set-short
test_brown : data/srl/samples/test-brown
test_wsj : data/srl/samples/test-wsj

max_train_length :  # maximum length of the training sentences, none or 100, 120, etc.

#### modify the path below
test: data/srl/samples/test-brown

extend_vob : # if we want to continue training on new dataset or predict on a new data with different vocabularies, we can choose to extend the vocabulary, so that the system can be benefit from the embeddings: Use empty if No, put True if Yes

[emb]
# phase 1, type can be word or  char
type : word
embedding_dim : 100
embedding_pred_dim : 100
#fix embeddings or not, if no: use "", else: "True"
train_word_embeddings : True
train_pred_embeddings : True
# path to the pre-trained embeddings, if use random values, then comment out the path
#word :
word : /home/quynh/Desktop/temp/glove.6B.100d.txt

# network sizes for learning character embeddings
# size of the character embeddings
hidden_char_dim : 100
#size of the word embeddings learned by using character sequence
embedding_char_dim : 100

[model]
# type of the model in phase 2: it can be rnn, or thirdparties
type : att
# type of the top: can be softmax or crf
top : softmax
layer_type : highway
hidden_dim : 200
learning_rate : 1.0
num_layers : 10
dropout_keep_prob : 0.9
nb_epochs : 500
batch_size : 80
batch_dev_size : 500
eval_freq : 1
patience : 100
num_buckets : 5
optimizer : adadelta
epsilon : 1e-06
learning_rate_decay_start : 400
learning_rate_decay_batch_step : 100
learning_rate_decay_step : 2
eval_script : scripts/srl/run_eval.sh
label_smoothing : 0.1
# all the words occurring less than a fixed number of times will be smoothed out
smooth_rare_words : 0


[inference]
# type of inference, for this version, only argmax (greedy) is available
type : argmax

[save]
model_dir : /home/quynh/Desktop/damesrl/att_final
#save frequency
save_freq : 10
# max no. of models can be saved
max_to_save : 1000


[log]
path : log.txt

[att]
residual_dropout : 0.2
attention_dropout : 0.1
relu_dropout : 0.1
filter_size : 1024
filter_width : 3
num_heads : 5
layer_preprocessor : none
layer_postprocessor : layer_norm
attention_function : dot_product
multiply_embedding_mode : sqrt_depth


[session]
mode : infer
# the model will be loaded from this checkpoint tag if exists. The tag can be "last", "best" or any other saved checkpoint srl-10, srl-20 etc.
tag : best


